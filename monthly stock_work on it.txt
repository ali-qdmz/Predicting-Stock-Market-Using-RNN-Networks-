# -*- coding: utf-8 -*-
"""
Created on Sat Nov 16 14:59:31 2019

@author: gadimzadeh
"""

import numpy  
import pandas as pd  
import math as m






#Moving Average  
def MA(df, n):  
    MA = pd.Series(df['Close'].rolling(n).mean(), name = 'MA_' + str(n))  
    df = df.join(MA)  
    return df

#Exponential Moving Average  
def EMA(df, n):  
    EMA = pd.Series(pd.ewma(df['Close'], span = n, min_periods = n - 1), name = 'EMA_' + str(n))  
    df = df.join(EMA)  
    return df

#Momentum  
def MOM(df, n):  
    M = pd.Series(df['Close'].diff(n), name = 'Momentum_' + str(n))  
    df = df.join(M)  
    return df

#Rate of Change  
def ROC(df, n):  
    M = df['Close'].diff(n - 1)  
    N = df['Close'].shift(n - 1)  
    ROC = pd.Series(M / N, name = 'ROC_' + str(n))  
    df = df.join(ROC)  
    return df

#Average True Range  
def ATR(df, n):  
    i = 0  
    TR_l = [0]  
    while i < df.index[-1]:  
        TR = max(df.get_value(i + 1, 'High'), df.get_value(i, 'Close')) - min(df.get_value(i + 1, 'Low'), df.get_value(i, 'Close'))  
        TR_l.append(TR)  
        i = i + 1  
    TR_s = pd.Series(TR_l)  
    ATR = pd.Series(pd.ewma(TR_s, span = n, min_periods = n), name = 'ATR_' + str(n))  
    df = df.join(ATR)  
    return df

#Bollinger Bands  
def BBANDS(df, n):  
    MA = pd.Series(pd.rolling_mean(df['Close'], n))  
    MSD = pd.Series(pd.rolling_std(df['Close'], n))  
    b1 = 4 * MSD / MA  
    B1 = pd.Series(b1, name = 'BollingerB_' + str(n))  
    df = df.join(B1)  
    b2 = (df['Close'] - MA + 2 * MSD) / (4 * MSD)  
    B2 = pd.Series(b2, name = 'Bollinger%b_' + str(n))  
    df = df.join(B2)  
    return df

#Pivot Points, Supports and Resistances  
def PPSR(df):  
    PP = pd.Series((df['High'] + df['Low'] + df['Close']) / 3)  
    R1 = pd.Series(2 * PP - df['Low'])  
    S1 = pd.Series(2 * PP - df['High'])  
    R2 = pd.Series(PP + df['High'] - df['Low'])  
    S2 = pd.Series(PP - df['High'] + df['Low'])  
    R3 = pd.Series(df['High'] + 2 * (PP - df['Low']))  
    S3 = pd.Series(df['Low'] - 2 * (df['High'] - PP))  
    psr = {'PP':PP, 'R1':R1, 'S1':S1, 'R2':R2, 'S2':S2, 'R3':R3, 'S3':S3}  
    PSR = pd.DataFrame(psr)  
    df = df.join(PSR)  
    return df

#Stochastic oscillator %K  
def STOK(df):  
    SOk = pd.Series((df['Close'] - df['Low']) / (df['High'] - df['Low']), name = 'SO%k')  
    df = df.join(SOk)  
    return df

# Stochastic Oscillator, EMA smoothing, nS = slowing (1 if no slowing)  
def STO(df,  nK, nD, nS=1):  
    SOk = pd.Series((df['Close'] - df['Low'].rolling(nK).min()) / (df['High'].rolling(nK).max() - df['Low'].rolling(nK).min()), name = 'SO%k'+str(nK))  
    SOd = pd.Series(SOk.ewm(ignore_na=False, span=nD, min_periods=nD-1, adjust=True).mean(), name = 'SO%d'+str(nD))  
    SOk = SOk.ewm(ignore_na=False, span=nS, min_periods=nS-1, adjust=True).mean()  
    SOd = SOd.ewm(ignore_na=False, span=nS, min_periods=nS-1, adjust=True).mean()  
    df = df.join(SOk)  
    df = df.join(SOd)  
    return df  
# Stochastic Oscillator, SMA smoothing, nS = slowing (1 if no slowing)  
def STO(df, nK, nD,  nS=1):  
    SOk = pd.Series((df['Close'] - df['Low'].rolling(nK).min()) / (df['High'].rolling(nK).max() - df['Low'].rolling(nK).min()), name = 'SO%k'+str(nK))  
    SOd = pd.Series(SOk.rolling(window=nD, center=False).mean(), name = 'SO%d'+str(nD))  
    SOk = SOk.rolling(window=nS, center=False).mean()  
    SOd = SOd.rolling(window=nS, center=False).mean()  
    df = df.join(SOk)  
    df = df.join(SOd)  
    return df  
#Trix  
def TRIX(df, n):  
    EX1 = pd.ewma(df['Close'], span = n, min_periods = n - 1)  
    EX2 = pd.ewma(EX1, span = n, min_periods = n - 1)  
    EX3 = pd.ewma(EX2, span = n, min_periods = n - 1)  
    i = 0  
    ROC_l = [0]  
    while i + 1 <= df.index[-1]:  
        ROC = (EX3[i + 1] - EX3[i]) / EX3[i]  
        ROC_l.append(ROC)  
        i = i + 1  
    Trix = pd.Series(ROC_l, name = 'Trix_' + str(n))  
    df = df.join(Trix)  
    return df

#Average Directional Movement Index  
def ADX(df, n, n_ADX):  
    i = 0  
    UpI = []  
    DoI = []  
    while i + 1 <= df.index[-1]:  
        UpMove = df.get_value(i + 1, 'High') - df.get_value(i, 'High')  
        DoMove = df.get_value(i, 'Low') - df.get_value(i + 1, 'Low')  
        if UpMove > DoMove and UpMove > 0:  
            UpD = UpMove  
        else: UpD = 0  
        UpI.append(UpD)  
        if DoMove > UpMove and DoMove > 0:  
            DoD = DoMove  
        else: DoD = 0  
        DoI.append(DoD)  
        i = i + 1  
    i = 0  
    TR_l = [0]  
    while i < df.index[-1]:  
        TR = max(df.get_value(i + 1, 'High'), df.get_value(i, 'Close')) - min(df.get_value(i + 1, 'Low'), df.get_value(i, 'Close'))  
        TR_l.append(TR)  
        i = i + 1  
    TR_s = pd.Series(TR_l)  
    ATR = pd.Series(pd.ewma(TR_s, span = n, min_periods = n))  
    UpI = pd.Series(UpI)  
    DoI = pd.Series(DoI)  
    PosDI = pd.Series(pd.ewma(UpI, span = n, min_periods = n - 1) / ATR)  
    NegDI = pd.Series(pd.ewma(DoI, span = n, min_periods = n - 1) / ATR)  
    ADX = pd.Series(pd.ewma(abs(PosDI - NegDI) / (PosDI + NegDI), span = n_ADX, min_periods = n_ADX - 1), name = 'ADX_' + str(n) + '_' + str(n_ADX))  
    df = df.join(ADX)  
    return df

#MACD, MACD Signal and MACD difference  
def MACD(df, n_fast, n_slow):  
    EMAfast = pd.Series(pd.ewma(df['Close'], span = n_fast, min_periods = n_slow - 1))  
    EMAslow = pd.Series(pd.ewma(df['Close'], span = n_slow, min_periods = n_slow - 1))  
    MACD = pd.Series(EMAfast - EMAslow, name = 'MACD_' + str(n_fast) + '_' + str(n_slow))  
    MACDsign = pd.Series(pd.ewma(MACD, span = 9, min_periods = 8), name = 'MACDsign_' + str(n_fast) + '_' + str(n_slow))  
    MACDdiff = pd.Series(MACD - MACDsign, name = 'MACDdiff_' + str(n_fast) + '_' + str(n_slow))  
    df = df.join(MACD)  
    df = df.join(MACDsign)  
    df = df.join(MACDdiff)  
    return df

#Mass Index  
def MassI(df):  
    Range = df['High'] - df['Low']  
    EX1 = Range.ewm(span = 9, min_periods = 8).mean()
    EX2 = EX1.ewm(span = 9, min_periods = 8).mean()
    Mass = EX1 / EX2  
    MassI = pd.Series(Mass.rolling(25).sum(), name = 'Mass Index')  
    df = df.join(MassI)  
    return df

#Vortex Indicator: http://www.vortexindicator.com/VFX_VORTEX.PDF  
def Vortex(df, n):  
    i = 0  
    TR = [0]  
    while i < df.index[-1]:  
        Range = max(df.get_value(i + 1, 'High'), df.get_value(i, 'Close')) - min(df.get_value(i + 1, 'Low'), df.get_value(i, 'Close'))  
        TR.append(Range)  
        i = i + 1  
    i = 0  
    VM = [0]  
    while i < df.index[-1]:  
        Range = abs(df.get_value(i + 1, 'High') - df.get_value(i, 'Low')) - abs(df.get_value(i + 1, 'Low') - df.get_value(i, 'High'))  
        VM.append(Range)  
        i = i + 1  
    VI = pd.Series(pd.rolling_sum(pd.Series(VM), n) / pd.rolling_sum(pd.Series(TR), n), name = 'Vortex_' + str(n))  
    df = df.join(VI)  
    return df





#KST Oscillator  
def KST(df, r1, r2, r3, r4, n1, n2, n3, n4):  
    M = df['Close'].diff(r1 - 1)  
    N = df['Close'].shift(r1 - 1)  
    ROC1 = M / N  
    M = df['Close'].diff(r2 - 1)  
    N = df['Close'].shift(r2 - 1)  
    ROC2 = M / N  
    M = df['Close'].diff(r3 - 1)  
    N = df['Close'].shift(r3 - 1)  
    ROC3 = M / N  
    M = df['Close'].diff(r4 - 1)  
    N = df['Close'].shift(r4 - 1)  
    ROC4 = M / N  
    KST = pd.Series(pd.rolling_sum(ROC1, n1) + pd.rolling_sum(ROC2, n2) * 2 + pd.rolling_sum(ROC3, n3) * 3 + pd.rolling_sum(ROC4, n4) * 4, name = 'KST_' + str(r1) + '_' + str(r2) + '_' + str(r3) + '_' + str(r4) + '_' + str(n1) + '_' + str(n2) + '_' + str(n3) + '_' + str(n4))  
    df = df.join(KST)  
    return df

#Relative Strength Index  
def RSI(df, n):  
    i = 0  
    UpI = [0]  
    DoI = [0]  
    while i + 1 <= df.index[-1]:  
        UpMove = df.get_value(i + 1, 'High') - df.get_value(i, 'High')  
        DoMove = df.get_value(i, 'Low') - df.get_value(i + 1, 'Low')  
        if UpMove > DoMove and UpMove > 0:  
            UpD = UpMove  
        else: UpD = 0  
        UpI.append(UpD)  
        if DoMove > UpMove and DoMove > 0:  
            DoD = DoMove  
        else: DoD = 0  
        DoI.append(DoD)  
        i = i + 1  
    UpI = pd.Series(UpI)  
    DoI = pd.Series(DoI)  
    PosDI = pd.Series(UpI.ewm(span = n, min_periods = n - 1).mean())  
    NegDI = pd.Series(DoI.ewm(span = n, min_periods = n - 1).mean())  
    RSI = pd.Series(PosDI / (PosDI + NegDI), name = 'RSI_' + str(n))  
    df = df.join(RSI)  
    return df

#True Strength Index  
def TSI(df, r, s):  
    M = pd.Series(df['Close'].diff(1))  
    aM = abs(M)  
    EMA1 = pd.Series(pd.ewma(M, span = r, min_periods = r - 1))  
    aEMA1 = pd.Series(pd.ewma(aM, span = r, min_periods = r - 1))  
    EMA2 = pd.Series(pd.ewma(EMA1, span = s, min_periods = s - 1))  
    aEMA2 = pd.Series(pd.ewma(aEMA1, span = s, min_periods = s - 1))  
    TSI = pd.Series(EMA2 / aEMA2, name = 'TSI_' + str(r) + '_' + str(s))  
    df = df.join(TSI)  
    return df

#Accumulation/Distribution  
def ACCDIST(df, n):  
    ad = (2 * df['Close'] - df['High'] - df['Low']) / (df['High'] - df['Low']) * df['Volume']  
    M = ad.diff(n - 1)  
    N = ad.shift(n - 1)  
    ROC = M / N  
    AD = pd.Series(ROC, name = 'Acc/Dist_ROC_' + str(n))  
    df = df.join(AD)  
    return df

#Chaikin Oscillator  
def Chaikin(df):  
    ad = (2 * df['Close'] - df['High'] - df['Low']) / (df['High'] - df['Low']) * df['Volume']  
    Chaikin = pd.Series(ad.ewm(span = 3, min_periods = 2).mean() - ad.ewm(span = 10, min_periods = 9).mean(), name = 'Chaikin')  
    df = df.join(Chaikin)  
    return df

#Money Flow Index and Ratio  
def MFI(df, n):  
    PP = (df['High'] + df['Low'] + df['Close']) / 3  
    i = 0  
    PosMF = [0]  
    while i < df.index[-1]:  
        if PP[i + 1] > PP[i]:  
            PosMF.append(PP[i + 1] * df.get_value(i + 1, 'Volume'))  
        else:  
            PosMF.append(0)  
        i = i + 1  
    PosMF = pd.Series(PosMF)  
    TotMF = PP * df['Volume']  
    MFR = pd.Series(PosMF / TotMF)  
    MFI = pd.Series(MFR.rolling(n).mean(), name = 'MFI_' + str(n))  
    df = df.join(MFI)  
    return df

#On-balance Volume  
def OBV(df, n):  
    i = 0  
    OBV = [0]  
    while i < df.index[-1]:  
        if df.get_value(i + 1, 'Close') - df.get_value(i, 'Close') > 0:  
            OBV.append(df.get_value(i + 1, 'Volume'))  
        if df.get_value(i + 1, 'Close') - df.get_value(i, 'Close') == 0:  
            OBV.append(0)  
        if df.get_value(i + 1, 'Close') - df.get_value(i, 'Close') < 0:  
            OBV.append(-df.get_value(i + 1, 'Volume'))  
        i = i + 1  
    OBV = pd.Series(OBV)  
    OBV_ma = pd.Series(pd.rolling_mean(OBV, n), name = 'OBV_' + str(n))  
    df = df.join(OBV_ma)  
    return df

#Force Index  
def FORCE(df, n):  
    F = pd.Series(df['Close'].diff(n) * df['Volume'].diff(n), name = 'Force_' + str(n))  
    df = df.join(F)  
    return df

#Ease of Movement  
def EOM(df, n):  
    EoM = (df['High'].diff(1) + df['Low'].diff(1)) * (df['High'] - df['Low']) / (2 * df['Volume'])  
    Eom_ma = pd.Series(pd.rolling_mean(EoM, n), name = 'EoM_' + str(n))  
    df = df.join(Eom_ma)  
    return df

#Commodity Channel Index  
def CCI(df, n):  
    PP = (df['High'] + df['Low'] + df['Close']) / 3  
    CCI = pd.Series((PP - pd.rolling_mean(PP, n)) / pd.rolling_std(PP, n), name = 'CCI_' + str(n))  
    df = df.join(CCI)  
    return df

#Coppock Curve  
def COPP(df, n):  
    M = df['Close'].diff(int(n * 11 / 10) - 1)  
    N = df['Close'].shift(int(n * 11 / 10) - 1)  
    ROC1 = M / N  
    M = df['Close'].diff(int(n * 14 / 10) - 1)  
    N = df['Close'].shift(int(n * 14 / 10) - 1)  
    ROC2 = M / N  
    Copp = pd.Series(pd.ewma(ROC1 + ROC2, span = n, min_periods = n), name = 'Copp_' + str(n))  
    df = df.join(Copp)  
    return df

#Keltner Channel  
def KELCH(df, n):  
    KelChM = pd.Series(pd.rolling_mean((df['High'] + df['Low'] + df['Close']) / 3, n), name = 'KelChM_' + str(n))  
    KelChU = pd.Series(pd.rolling_mean((4 * df['High'] - 2 * df['Low'] + df['Close']) / 3, n), name = 'KelChU_' + str(n))  
    KelChD = pd.Series(pd.rolling_mean((-2 * df['High'] + 4 * df['Low'] + df['Close']) / 3, n), name = 'KelChD_' + str(n))  
    df = df.join(KelChM)  
    df = df.join(KelChU)  
    df = df.join(KelChD)  
    return df

#Ultimate Oscillator  
def ULTOSC(df):  
    i = 0  
    TR_l = [0]  
    BP_l = [0]  
    while i < df.index[-1]:  
        TR = max(df.get_value(i + 1, 'High'), df.get_value(i, 'Close')) - min(df.get_value(i + 1, 'Low'), df.get_value(i, 'Close'))  
        TR_l.append(TR)  
        BP = df.get_value(i + 1, 'Close') - min(df.get_value(i + 1, 'Low'), df.get_value(i, 'Close'))  
        BP_l.append(BP)  
        i = i + 1  
    UltO = pd.Series((4 * pd.Series(BP_l).rolling(7).sum() / pd.Series(TR_l).rolling(7).sum()) + (2 * pd.Series(BP_l).rolling(14).sum() / pd.Series(TR_l).rolling(14).sum()) + (pd.Series(BP_l).rolling(28).sum() / pd.Series(TR_l).rolling(28).sum()), name = 'Ultimate_Osc')  
    df = df.join(UltO)  
    return df

#Donchian Channel  
def DONCH(df, n):  
    i = 0  
    DC_l = []  
    while i < n - 1:  
        DC_l.append(0)  
        i = i + 1  
    i = 0  
    while i + n - 1 < df.index[-1]:  
        DC = max(df['High'].ix[i:i + n - 1]) - min(df['Low'].ix[i:i + n - 1])  
        DC_l.append(DC)  
        i = i + 1  
    DonCh = pd.Series(DC_l, name = 'Donchian_' + str(n))  
    DonCh = DonCh.shift(n - 1)  
    df = df.join(DonCh)  
    return df

#Standard Deviation  
def STDDEV(df, n):  
    df = df.join(pd.Series(pd.rolling_std(df['Close'], n), name = 'STD_' + str(n)))  
    return df  


def isNaN(num):
    return num != num


import datetime
import pandas as pd
from sklearn import preprocessing
import numpy as np
from keras.models import load_model
history_points = 4

def csv_to_dataset(csv_path):
    
    df1 = pd.read_csv("test.csv", parse_dates =["Date"], index_col="Date")
    df1 =df1.drop('Unnamed: 0' , axis = 1)
    
    test = pd.DataFrame()
    test['Open'] = df1.Open.resample('W',how='first',fill_method='bfill')
    test['High'] = df1.High.resample('W',how='max',fill_method='bfill')
    test['Low'] = df1.Low.resample('W',how='min',fill_method='bfill')
    test['Close'] = df1.Close.resample('W',how='last',fill_method='bfill')
    test['Volume'] = df1.Volume.resample('W',how='sum',fill_method='bfill')



    df1 = pd.DataFrame()
    df1['Open'] = test['Open']
    df1['High'] = test['High']
    df1['Low'] = test['Low']
    df1['Close'] = test['Close']
    df1['Volume'] = test['Volume']
    df1.index = df1.index.date
    df1.index = range(len(df1))
    i = df1[((df1.Open == 3805.0) &( df1.High == 3850.0) & (df1.Low ==3790.0))].index

    df1 = df1.drop(i)
    for item in df1['Volume']:
        if isNaN(item):
            print(1)
    df1 = MA(df1,2)
    df1 = RSI(df1,14)
    df1 = Chaikin(df1)
    #df1 = MFI(df1,10)
    for i in range(20):
        df1 = df1.drop(df1.index[0])
    df1.index = range(len(df1))
    print(df1.isnull().sum().sum())
    data_normaliser = preprocessing.MinMaxScaler()
    data_normalised = data_normaliser.fit_transform(df1)
    
    ohlcv_histories_normalised =      np.array([data_normalised[i  : i + history_points].copy() for i in range(len(data_normalised) - history_points)])
    tomorow = np.array([data_normalised[len(data_normalised)-history_points:len(data_normalised)]])
    #next_day_open_values_normalised = np.array([data_normalised[:,3][i + history_points].copy() for i in range(len(data_normalised) - history_points)]) 
    #next_day_open_values_normalised = np.expand_dims(next_day_open_values_normalised, -1)
    
    next_day_open_values = np.array([df1['Open'][i + history_points].copy() for i in range(len(df1) - history_points)])
    #next_day_open_values = next_day_open_values_normalised
    
    y_normaliser = preprocessing.MinMaxScaler()
    next_day_open_values_normalised = y_normaliser.fit_transform(np.array(df1['Open'][history_points:]).reshape(-1, 1))
 
 
    

  
        


    
    
    
    assert ohlcv_histories_normalised.shape[0] == next_day_open_values_normalised.shape[0]
    return df1,tomorow,data_normaliser,ohlcv_histories_normalised, next_day_open_values_normalised, next_day_open_values,y_normaliser


def inverse_return(obj):
    trainPredict_dataset_like2 = np.zeros(shape=(len(obj), 5) )
# put the predicted values in the right field
    trainPredict_dataset_like2[:,3] = obj[:,3]
# inverse transform and then select the right field
    real = data_normaliser.inverse_transform(trainPredict_dataset_like2)[:,3]
    return real




df,tomorow,data_normalizer,ohlcv_histories, next_day_open_values, unscaled_y,y_normalizer = csv_to_dataset('akhaber.csv')




    
    
test_split = 0.9
n = int(ohlcv_histories.shape[0] * test_split)

ohlcv_train = ohlcv_histories[:n]

y_train = next_day_open_values[:n]

ohlcv_test = ohlcv_histories[n:]

y_test = next_day_open_values[n:]

unscaled_y_test = unscaled_y[n:]






# =============================================================================
# 
# =============================================================================
# import keras
# import tensorflow as tf
# from keras.models import Model
# from keras.layers import Dense, Dropout, LSTM, Input, Activation, concatenate
# from keras import optimizers
# import numpy as np
# np.random.seed(4)
# from tensorflow import set_random_seed
# set_random_seed(4)
# 
# lstm_input = Input(shape=(history_points, 9), name='lstm_input')
# x = LSTM(80, name='lstm_0')(lstm_input)
# x = Dropout(0.2, name='lstm_dropout_0')(x)
# x = Dense(40, name='dense_0')(x)
# x = Activation('sigmoid', name='sigmoid_0')(x)
# x = Dense(1, name='dense_1')(x)
# output = Activation('linear', name='linear_output')(x)
# model = Model(inputs=lstm_input, outputs=output)
#  
# 
# adam = optimizers.Adam(lr=0.0005)
# 
# model.compile(optimizer=adam,
#               loss='mse')
# 
# 
# model.fit(x=ohlcv_train, y=y_train, batch_size=64, epochs=1000, shuffle=True, validation_split=0.1)
# evaluation = model.evaluate(ohlcv_test, y_test)
# print(evaluation)
# model.save('akhaber_with_technical.h5')
# 
# y = y_normalizer.inverse_transform(model.predict(ohlcv_histories))
# real_mse = np.mean(np.square(unscaled_y - y))
# print("mse is :",real_mse)
# 
# l = []
# j = 200
# for i in range(1900,2100):
#     if y[i+1]-y[i]  > 0 and unscaled_y[i+1] - unscaled_y[i]>0:
#         l.append(True)
#     if y[i+1]-y[i]  < 0 and unscaled_y[i+1] - unscaled_y[i]<0:
#         l.append(True)
#         
# print(l.count(True),"/",j)
# print((float(l.count(True))/float(j)) * 100 , "percent aacuracy")
# 
# =============================================================================
# =============================================================================
# =============================================================================
# ohlcv_histories = np.append(ohlcv_histories,tomorow,axis=0)
# tomorrow_forecast = y_normalizer.inverse_transform(model.predict(ohlcv_histories[len(ohlcv_histories)-1:]))
# print("tommoroow is" ,tomorrow_forecast)
# =============================================================================

# =============================================================================
# # =============================================================================
# =============================================================================
# 
# 
# 
# 
# y_test_predicted = model.predict(ohlcv_histories)
# pred = inverse_return(y_test_predicted)
# 
# unscaled_y.shape = y_test_predicted.shape
# 
# real = inverse_return(unscaled_y)
# 
# 
# 
# pred_buffer = pred
# real_buffer = real
# 
# real_mse = np.mean(np.square(real - pred))
# scaled_mse = real_mse / (np.max(real) - np.min(real)) * 100
# 
# print(real_mse , scaled_mse)
# 
# start = 0
# end = 990
# 
# 
# buys = []
# sells = []
# thresh = 0.1
# q = 0
# x = 0
# for ohlcv in zip(ohlcv_histories[start: end]):
#     normalised_price_today = ohlcv[-1][0]
#     normalised_price_today = np.array([[normalised_price_today]])
#     price_today = real_buffer[q]
#     predicted = pred_buffer[q]
#     delta = predicted - price_today
#     # print(delta)
#     if delta > thresh:
#         buys.append((x, price_today))
#     elif delta < -thresh:
#         sells.append((x, price_today))
#     x += 1
#     q += 1
# 
# 
# 
# 
# def compute_earnings(buys_, sells_):
#     purchase_amt = 10
#     stock = 0
#     balance = 0
#     while len(buys_) > 0 and len(sells_) > 0:
#         if buys_[0][0] < sells_[0][0]:
#             # time to buy $10 worth of stock
#             balance -= purchase_amt
#             stock += purchase_amt / buys_[0][1]
#             buys_.pop(0)
#         else:
#             # time to sell all of our stock
#             balance += stock * sells_[0][1]
#             stock = 0
#             sells_.pop(0)
#     print(f"earnings: ${balance}")
# 
# 
# 
# compute_earnings([b for b in buys], [s for s in sells])
# 
# 
# import matplotlib.pyplot as plt
# 
# plt.gcf().set_size_inches(22, 15, forward=True)
# 
# real = plt.plot(real_buffer[start:end], label='real')
# pred = plt.plot(pred_buffer[start:end], label='predicted')
# 
# if len(buys) > 0:
#     plt.scatter(list(list(zip(*buys))[0]), list(list(zip(*buys))[1]), c='#00ff00', s=50)
# if len(sells) > 0:
#     plt.scatter(list(list(zip(*sells))[0]), list(list(zip(*sells))[1]), c='#ff0000', s=50)
# 
# # real = plt.plot(unscaled_y[start:end], label='real')
# # pred = plt.plot(y_predicted[start:end], label='predicted')
# 
# plt.legend(['Real', 'Predicted', 'Buy', 'Sell'])
# 
# plt.show()
# 
# #command to predict
# #inverse_return(model.predict([[ohlcv_histories[233]], [technical_indicators[233]]]))
# 
# thresh = 0.1
# predict = []
# today = []
# 
# 
# start = 900
# end = 990
# 
# 
# 
# 
# columns = []
# x = 0
# for q in range(5000):
#     if end != -1:
#         iter = end - start
#     else:
#         iter = 991
#     buys = []
#     sells = []
#     for k in range(start,end):
#         
#         delta = pred_buffer[k] - real_buffer[k]
#         # print(delta)
#         if delta > thresh:
#             buys.append((x, real_buffer[k]))
#         elif delta < -thresh:
#             sells.append((x, real_buffer[k]))
#         x += 1    
#         
#         
#     def compute_earnings(buys_, sells_):
#         purchase_amt = 10
#         stock = 0
#         balance = 0
#         while len(buys_) > 0 and len(sells_) > 0:
#             if buys_[0][0] < sells_[0][0]:
#                 # time to buy $10 worth of stock
#                 balance -= purchase_amt
#                 stock += purchase_amt / buys_[0][1]
#                 buys_.pop(0)
#             else:
#                 # time to sell all of our stock
#                 balance += stock * sells_[0][1]
#                 stock = 0
#                 sells_.pop(0)
#         #print(f"earnings: ${balance}")
#         return balance
#     
#     
#     
#     blc = compute_earnings([b for b in buys], [s for s in sells])
#     columns.append((blc,thresh))
#     thresh = thresh + 0.1
# y = dict(columns)
# y_1 = np.array(list(y.keys()))
# print("get ",y_1.max(),"for thresh = ",y[y_1.max()])
# 
# 
# ################
# 
# 
# 
# thresh = 0.1
# predict = []
# today = []
# 
# 
# start = 900
# end = 990
# 
# 
# 
# 
# columns = []
# x = 0
# #for ohlcv, ind in zip(ohlcv_histories[start: end], technical_indicators[start: end]):
# #    normalised_price_today = ohlcv[-1][0]
# #    normalised_price_today = np.array([[normalised_price_today]])
# #    price_today = inverse_return(normalised_price_today)
# #    today.append(price_today)
# #    predicted = np.squeeze(inverse_return( model.predict([[ohlcv], [ind]])))
# #    predict.append(predicted)
# 
# 
# 
# def optimizer(start=0,end=len(pred_buffer),epoch=5000,thresh = 0.1,step=0.1):
# 
#    
#     columns = []
#     x = 0
#     for q in range(5000):
#         if end != -1:
#             iter = end - start
#         else:
#             iter = 991
#         buys = []
#         sells = []
#         for k in range(start,end):
#             
#             delta = pred_buffer[k] - real_buffer[k]
#             # print(delta)
#             if delta > thresh:
#                 buys.append((x, real_buffer[k]))
#             elif delta < -thresh:
#                 sells.append((x, real_buffer[k]))
#             x += 1    
#             
#             
#         def compute_earnings(buys_, sells_):
#             purchase_amt = 10
#             stock = 0
#             balance = 0
#             while len(buys_) > 0 and len(sells_) > 0:
#                 if buys_[0][0] < sells_[0][0]:
#                     # time to buy $10 worth of stock
#                     balance -= purchase_amt
#                     stock += purchase_amt / buys_[0][1]
#                     buys_.pop(0)
#                 else:
#                     # time to sell all of our stock
#                     balance += stock * sells_[0][1]
#                     stock = 0
#                     sells_.pop(0)
#             #print(f"earnings: ${balance}")
#             return balance
#         
#         
#         
#         blc = compute_earnings([b for b in buys], [s for s in sells])
#         columns.append((blc,thresh))
#         thresh = thresh + step
#     y = dict(columns)
#     y_1 = np.array(list(y.keys()))
#     print("get ",y_1.max(),"for thresh = ",y[y_1.max()])
#     
#     
#     
# result = []    
# def grapher(start=0,end=len(pred_buffer),thresh=0):
#     
#     buys = []
#     sells = []
#     q = start
#     x = 0
# 
#     for ohlcv in zip(ohlcv_histories[start: end]):
#         normalised_price_today = ohlcv[-1][0]
#         normalised_price_today = np.array([[normalised_price_today]])
#         price_today = real_buffer[q]
#         predicted = pred_buffer[q]
#         delta = pred_buffer[q] - pred_buffer[q-1]
#         if q != len(real_buffer)-1:
#             delta_real = real_buffer[q+1] - real_buffer[q]
#         
#         # print(delta)
#         if delta > thresh:
#             buys.append((x, price_today))
#             if q != len(real_buffer)-1:
#                 if delta_real > 0:
#                     result.append(True)
#                 if delta_real < 0:
#                     result.append(False)
#             
#         elif delta < -thresh:
#             if q != len(real_buffer)-1:
#                 if delta_real < 0:
#                     result.append(True)
#                 if delta_real > 0:
#                     result.append(False)            
#             sells.append((x, price_today))
#         x += 1
#         q += 1
#     
#     
#     
#     
#     def compute_earnings(buys_, sells_):
#         purchase_amt = 10
#         stock = 0
#         balance = 0
#         while len(buys_) > 0 and len(sells_) > 0:
#             if buys_[0][0] < sells_[0][0]:
#                 # time to buy $10 worth of stock
#                 balance -= purchase_amt
#                 stock += purchase_amt / buys_[0][1]
#                 buys_.pop(0)
#             else:
#                 # time to sell all of our stock
#                 balance += stock * sells_[0][1]
#                 stock = 0
#                 sells_.pop(0)
#         print(f"earnings: ${balance}")
#         
# 
#     
#     
#     
#     compute_earnings([b for b in buys], [s for s in sells])
#     
#     
#     import matplotlib.pyplot as plt
#     
#     plt.gcf().set_size_inches(22, 15, forward=True)
#     
#     real = plt.plot(real_buffer[start:end], label='real')
#     pred = plt.plot(range(1,1+len(pred_buffer[start:end])),pred_buffer[start:end], label='predicted')
#     
#     if len(buys) > 0:
#         plt.scatter(list(list(zip(*buys))[0]), list(list(zip(*buys))[1]), c='#00ff00', s=50)
#     if len(sells) > 0:
#         plt.scatter(list(list(zip(*sells))[0]), list(list(zip(*sells))[1]), c='#ff0000', s=50)
#     
#     # real = plt.plot(unscaled_y[start:end], label='real')
#     # pred = plt.plot(y_predicted[start:end], label='predicted')
#     
#     plt.legend(['Real', 'Predicted', 'Buy', 'Sell'])
#     
#     plt.show()
#     print("Trues : " , result.count(True))
#     print("Falses : " , result.count(False))
#     result.clear()
#     
#     
#     
# #=====================================================================
# def test(thresh,start = 0,end = 990):
#     q = start
#     
#     
#     buys = []
#     sells = []
# 
#     x = 0
#     for ohlcv in zip(ohlcv_histories[start: end]):
#         normalised_price_today = ohlcv[-1][0]
#         normalised_price_today = np.array([[normalised_price_today]])
#         price_today = real_buffer[q]
#         predicted = pred_buffer[q]
#         delta = predicted - price_today
#         # print(delta)
#         if delta > thresh:
#             buys.append((x, price_today))
#         elif delta < -thresh:
#             sells.append((x, price_today))
#         x += 1
#         q += 1
#     
#     
#     
#     
#     def compute_earnings(buys_, sells_):
#         purchase_amt = 10
#         stock = 0
#         balance = 0
#         while len(buys_) > 0 and len(sells_) > 0:
#             if buys_[0][0] < sells_[0][0]:
#                 # time to buy $10 worth of stock
#                 balance -= purchase_amt
#                 stock += purchase_amt / buys_[0][1]
#                 buys_.pop(0)
#             else:
#                 # time to sell all of our stock
#                 balance += stock * sells_[0][1]
#                 stock = 0
#                 sells_.pop(0)
#         return balance
#     
#     
#     
#     return compute_earnings([b for b in buys], [s for s in sells])    
# 
# 
# 
# 
# def maxmin(f,a,b,n,start,end):
#     import operator
#     x = []
#     for i in np.linspace(a, b, n):
#         x.append(f(i,start,end))
#     index, maximum = max(enumerate(x), key=operator.itemgetter(1))
#     index2, minimum = min(enumerate(x), key=operator.itemgetter(1))
#     x = np.linspace(a, b, n)
#     print("get ",maximum," for thresh = ",x[index])
#     print("get ",minimum," for thresh = ",x[index2])
#     
#     return (maximum,index),(minimum,index2)
# 
# 
# 
# =============================================================================

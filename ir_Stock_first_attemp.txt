# -*- coding: utf-8 -*-
"""
Created on Mon Oct 28 14:26:49 2019

@author: gadimzadeh
"""

from alpha_vantage.timeseries import TimeSeries
import json


def save_dataset(symbol):


    ts = TimeSeries(key='ME4NPOSQIEI6WCNZ', output_format='pandas')
    data, meta_data = ts.get_daily(symbol, outputsize='full')

    data.to_csv(f'./]symbol}_daily.csv')
    
    
#save_dataset('MSFT')


import pandas as pd
from sklearn import preprocessing
import numpy as np

history_points = 80

def csv_to_dataset(csv_path):
    global history_points
    global data_normaliser
    global data_normalised
    data = pd.read_csv(csv_path)
    data = data.drop('<DTYYYYMMDD>', axis=1)
    data = data.drop('Unnamed: 0', axis=1)
    data = data.drop('Unnamed: 12', axis=1)
    data = data.drop(0, axis=0)
    data.columns = ['1. open', '2. high', '3. low', '4. close', '5. volume', '6. nbnum', '7. nbsum',
       '8. nbval', '9. nsval', '10. jton']
    
    data_normaliser = preprocessing.MinMaxScaler()
    data_normalised = data_normaliser.fit_transform(data)
    
    ohlcv_histories_normalised =      np.array([data_normalised[i  : i + history_points].copy() for i in range(len(data_normalised) - history_points)])
    next_day_open_values_normalised = np.array([data_normalised[:,0][i + history_points].copy() for i in range(len(data_normalised) - history_points)]) 
    #next_day_open_values_normalised = np.expand_dims(next_day_open_values_normalised, -1)
    
    next_day_open_values = np.array([data['1. open'][i + history_points].copy() for i in range(len(data) - history_points)])
    next_day_open_values = next_day_open_values_normalised
    
    #y_normaliser = preprocessing.MinMaxScaler()
    #y_normaliser.fit_transform(np.expand_dims( next_day_open_values , -1))
 
    def calc_ema(values, time_period):
        # https://www.investopedia.com/ask/answers/122314/what-exponential-moving-average-ema-formula-and-how-ema-calculated.asp
        sma = np.mean(values[:,3])
        ema_values = [sma]
        k = 2 / (1 + time_period)
        for i in range(len(his) - time_period, len(his)):
            close = his[i][3]
            ema_values.append(close * k + ema_values[-1] * (1 - k))
        return ema_values[-1]
		 
    
    
    technical_indicators = []
    for his in ohlcv_histories_normalised:
        # since we are using his[3] we are taking the SMA of the closing price
        sma = np.mean(his[:,3])
        macd = calc_ema(his, 12) - calc_ema(his, 26)
        
        technical_indicators.append(np.array([sma,macd,]))   

    technical_indicators = np.array(technical_indicators)
    global tech_ind_scaler
    tech_ind_scaler = preprocessing.MinMaxScaler()
    technical_indicators_normalised = tech_ind_scaler.fit_transform(technical_indicators)
    
    
    
    assert ohlcv_histories_normalised.shape[0] == next_day_open_values_normalised.shape[0] == technical_indicators_normalised.shape[0]
    return ohlcv_histories_normalised, technical_indicators_normalised, next_day_open_values_normalised, next_day_open_values







ohlcv_histories, technical_indicators, next_day_open_values, unscaled_y = csv_to_dataset('b.csv')

test_split = 0.9
n = int(ohlcv_histories.shape[0] * test_split)

ohlcv_train = ohlcv_histories[:n]
tech_ind_train = technical_indicators[:n]
y_train = next_day_open_values[:n]

ohlcv_test = ohlcv_histories[n:]
tech_ind_test = technical_indicators[n:]
y_test = next_day_open_values[n:]

unscaled_y_test = unscaled_y[n:]






import keras
import tensorflow as tf
from keras.models import Model
from keras.layers import Dense, Dropout, LSTM, Input, Activation, concatenate
from keras import optimizers
import numpy as np
np.random.seed(4)
from tensorflow import set_random_seed
set_random_seed(4)

# define two sets of inputs
lstm_input = Input(shape=(history_points, 10), name='lstm_input')
dense_input = Input(shape=(technical_indicators.shape[1],), name='tech_input')
 
# the first branch operates on the first input
x = LSTM(50, name='lstm_0')(lstm_input)
x = Dropout(0.2, name='lstm_dropout_0')(x)
lstm_branch = Model(inputs=lstm_input, outputs=x)
 
# the second branch opreates on the second input
y = Dense(20, name='tech_dense_0')(dense_input)
y = Activation("relu", name='tech_relu_0')(y)
y = Dropout(0.2, name='tech_dropout_0')(y)
technical_indicators_branch = Model(inputs=dense_input, outputs=y)
 
# combine the output of the two branches
combined = concatenate([lstm_branch.output, technical_indicators_branch.output], name='concatenate')
 
z = Dense(64, activation="sigmoid", name='dense_pooling')(combined)
z = Dense(1, activation="linear", name='dense_out')(z)
 
# our model will accept the inputs of the two branches and then output a single value
model = Model(inputs=[lstm_branch.input, technical_indicators_branch.input], outputs=z)

adam = optimizers.Adam(lr=0.0005)

model.compile(optimizer=adam,
              loss='mse')


model.fit(x=[ohlcv_train, tech_ind_train], y=y_train, batch_size=32, epochs=50, shuffle=True, validation_split=0.1)
evaluation = model.evaluate([ohlcv_test, tech_ind_test], y_test)
print(evaluation)



y_test_predicted = model.predict([ohlcv_histories,technical_indicators])


unscaled_y.shape = y_test_predicted.shape

#scaled_mse = real_mse / (np.max(unscaled_y_test) - np.min(unscaled_y_test)) * 100


# create empty table with 12 fields
trainPredict_dataset_like = np.zeros(shape=(len(y_test_predicted), 10) )
# put the predicted values in the right field
trainPredict_dataset_like[:,0] = y_test_predicted[:,0]
# inverse transform and then select the right field
pred = data_normaliser.inverse_transform(trainPredict_dataset_like)[:,0]



# create empty table with 12 fields
trainPredict_dataset_like2 = np.zeros(shape=(len(unscaled_y), 10) )
# put the predicted values in the right field
trainPredict_dataset_like2[:,0] = unscaled_y[:,0]
# inverse transform and then select the right field
real = data_normaliser.inverse_transform(trainPredict_dataset_like2)[:,0]

real_buffer = real
pred_buffer = pred


def inverse_return(obj):
    trainPredict_dataset_like2 = np.zeros(shape=(len(obj), 10) )
# put the predicted values in the right field
    trainPredict_dataset_like2[:,0] = obj[:,0]
# inverse transform and then select the right field
    real = data_normaliser.inverse_transform(trainPredict_dataset_like2)[:,0]
    return real
    
real_mse = np.mean(np.square(real - pred))
scaled_mse = real_mse / (np.max(real) - np.min(real)) * 100

print(real_mse , scaled_mse)


start = 0
end = -1



buys = []
sells = []
thresh = 0.1



x = 0
for ohlcv, ind in zip(ohlcv_histories[start: end], technical_indicators[start: end]):
    normalised_price_today = ohlcv[-1][0]
    normalised_price_today = np.array([[normalised_price_today]])
    price_today = inverse_return(normalised_price_today)
    predicted = np.squeeze(inverse_return( model.predict([[ohlcv], [ind]])))
    delta = predicted - price_today
    # print(delta)
    if delta > thresh:
        buys.append((x, price_today[0]))
    elif delta < -thresh:
        sells.append((x, price_today[0]))
    x += 1
print(len(buys))
print(len(sells))


def compute_earnings(buys_, sells_):
    purchase_amt = 10
    stock = 0
    balance = 0
    while len(buys_) > 0 and len(sells_) > 0:
        if buys_[0][0] < sells_[0][0]:
            # time to buy $10 worth of stock
            balance -= purchase_amt
            stock += purchase_amt / buys_[0][1]
            buys_.pop(0)
        else:
            # time to sell all of our stock
            balance += stock * sells_[0][1]
            stock = 0
            sells_.pop(0)
    print(f"earnings: $]balance}")



compute_earnings([b for b in buys], [s for s in sells])

import matplotlib.pyplot as plt

plt.gcf().set_size_inches(22, 15, forward=True)

real = plt.plot(real_buffer[start:end], label='real')
pred = plt.plot(pred_buffer[start:end], label='predicted')

if len(buys) > 0:
    plt.scatter(list(list(zip(*buys))[0]), list(list(zip(*buys))[1]), c='#00ff00', s=50)
if len(sells) > 0:
    plt.scatter(list(list(zip(*sells))[0]), list(list(zip(*sells))[1]), c='#ff0000', s=50)

# real = plt.plot(unscaled_y[start:end], label='real')
# pred = plt.plot(y_predicted[start:end], label='predicted')

plt.legend(['Real', 'Predicted', 'Buy', 'Sell'])

plt.show()